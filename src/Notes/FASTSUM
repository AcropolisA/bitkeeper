Encode non-ChangeSet sfile weave to optimize checksum calculation.

Speed up checksums
------------------

Takepatch has been enhanced over time to bring a whole sfio
when it is a new file and stream of patches when it is not.
The stream of patches can be injected into the weave in one pass,
saving the overhead of the original stripdel and repatching.

This moved the overhead in a big pull to the checksum verification for
each delta brought over in the patch.  In takepatch there is a loop
calling sccs_resum(s, d) per delta brought in, sccs_resum() in turn
calls sccs_get() with some flags which cause it to not get the
contents of the file, but just to verify the checksum.  That operation
was walking the whole weave on each call.

To speed up the process, fastsum() was wired into get_reg() if the
conditions were just right (basically, the conditions that
sccs_resum() sets up).  The first time fastsum is called, it sets up a
cache of the weave where datablocks are replaced with checksums and
linecounts of the blocks.  Subsequent calls then use the cache to
compute d->sum, d->added, d->same, and d->deleted.

Handling a no newline file
--------------------------

The cache needs to run the same nonewline state machine that get_reg()
does but gets to cheat a little.  When we are writing a file out, we
can't put the newline out until we are in the right place in the file.
Calculating a checksum, we can add the newline in right away, then
subtract '\n' at the end if the no newline state machine says so.

The way it works is to keep a variable 'lf_pend' which has
the serial number of the last block of data printed.  That
variable will get set to 0 in two conditions: if a deleted
portion of that same level of data is seen, and if an ^AE
is seen closing down that block.

In the latter case, when a block which set lf_pends ends,
and there was an 'N' found after the serial number (when the
cache was built), the no_lf flag is set.  This stays set until
any other active data is seen.

If no_lf is set at the end, then we subtract '\n' from the sum.

You may be wondering why get_reg() uses lf_pend, but not the no_lf
flag.  The no_lf is needed in fastsum() because of the I compression.
In get_reg(), there is only one E with the same serial as lf_pend.  But
with the I compression, the matching E might have been removed.  We
detect closing blocks by the step down to a lower serial number. 
However there can be many cases where a step down occurs.  Only the
first one is the real one, so when it is seen, lf_pend is cleared, and
no_lf is set.   

Packing the weave
-----------------

There are a number of optimizations we can do as we are not
restricted to maintaining sccs structure.

== Version 1

The weave is represented in an array of 32 bit unsigned ints.
Each SCCS command takes a u32 and each block of data (upto 2^15 - 1
lines long) takes a u32.

commands         MSB
^AD <serial>   => 1  0  0  <29 bits of serial>
^AI <serial>   => 1  0  1  <29 bits of serial>
^AE <serial>   => 1  1  0  <29 bits of serial>
^AE <serial>N  => 1  1  1  <29 bits of serial>

data blocks	 MSB
bla bla bla
bla bla bla
bla bla bla    => 0 <15 bits line count> <16 checksum>

Then walking the weave uses the same changestate/printstate as get_reg()
with one change that printstate can be put with the data block, since
there is typically one datablock between commands.  This reduces the
number of printstate calls down.  Example:

^AD 3
This is the old text
that used to be here
^AE 3
^AI 3
This is the new text
that is now here
^AE 3

Calling printstate with every command means it would be called 4 times,
and calling it with each data block means it is called twice.

== Version 2

When version 1 was pulled into 'dev' the performance took a dive.
Leading the way was changestate() with 250 million calls for a big patch.
The data structure for state has been changed from a handcrafted linked
list to a dynamically allocate u32 array.  This changed meant a big
slowdown for a 1/4 billion calls (takepatch went from 12 to 16 seconds).

It's easy to drop the number of changestate calls because not every
command needs to go in.  The way I-E pairs are in the weave are
a pure stack -- push for I, pop for E.  That allows for a replacement
for a sequence like
 	I1 .. I2 .. I3 .. E3 E2 E1
with using I followed by the serial number that is now active:
	I1 .. I2 .. I3 .. I2 I1 I0

Storing this structure in the cache means the cache walker wouldn't
need to use changestate to recover what serial contributed the next
data block.  Instead, a 'cur' variable keeps the current level.

To do the no newline processing, we need to recognize the old E command.
That is done by seeing that the serial number is dropping.  The cache
making asserts this is true, and so it can be relied on when cache walking.
The 'N' tag now moves from E to I, which takes some jostling of the
way things are stored by swapping I and E:

commands         MSB
^AD <serial>   => 1  0  0  <29 bits of serial>
^AE <serial>   => 1  0  1  <29 bits of serial>
^AI <serial>   => 1  1  0  <29 bits of serial>
^AI <serial>N  => 1  1  1  <29 bits of serial>

Doing this, changestate is only used to track D<ser>-E<ser> pairs,
and not all D-E pairs, but only active ones (where slist[ser] is true).

The only item that needs to be tracked is the active delete with
the largest serial.  If we are only storing active, then that would
be the top element of state if there is one.

The tracking of the deleted counter needed to look at the next biggest
delete.  I could have created another interface to look at the next
biggest, but instead I set it up to cache the top of the state list
locally in dstate and use the state structure to store all the other
deletes.  This lets me use topstate to get at the second delete in the
list.  This change also increases performance since changestate is
called even less.  If there are no overlapping active deletes,
changestate is never called.

Doing all of this dropped the number of calls to changestate from
around 250 million to 45 million (before the deleted enhancement).
This dropped the just under 12 seconds to around 6 seconds for the
bugfix version, and just below 16 seconds to just above 6 seconds for
the dev version.  It closed a 4 second gap to just above 1/2 second. 

== Version 3

Compress I sequences.  After the I-E -> I-I transform, a weave can
look like:

^I 5
a new first line
^I 6
more foo
^I 5
^I 0
^I 2
first line
^I 0
^I 1
^I 0

With compression:
^I 5
a new first line
^I 6
more foo
^I 2
first line
^I 0

As explained earlier, the no-newline machine was adjusted to work with
this, by splitting out the tracker lf_pend with the final state of
no_lf.  This lets the stopping condition not need to match the data
serial state, but just be less than it. 

The building of the cache has an assert (ser < last) which
verifies this assumption.

The compression works with no newline by only collapsing
I<serial>[N] if neither have the N or both have the N.
